{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e04d8b97",
   "metadata": {},
   "source": [
    "### Create a program to implement the working of RNN - prediction of words from the paragraph provided.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cd33720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: machine learning is a method of data analysis\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Sample paragraph\n",
    "paragraph = \"\"\"\n",
    "Machine learning is a method of data analysis that automates analytical model building. \n",
    "Using algorithms that iteratively learn from data, machine learning allows computers to find hidden insights \n",
    "without being explicitly programmed where to look.\n",
    "\"\"\"\n",
    "\n",
    "# Step 1: Tokenization (word-level)\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([paragraph])\n",
    "word_index = tokenizer.word_index\n",
    "index_word = {v: k for k, v in word_index.items()}\n",
    "\n",
    "# Convert paragraph to sequence of word indices\n",
    "tokens = tokenizer.texts_to_sequences([paragraph])[0]\n",
    "\n",
    "# Step 2: Prepare sequences for training\n",
    "X_sequences = []\n",
    "y = []\n",
    "\n",
    "seq_length = 3  # You can change this to 4 or more for longer context\n",
    "\n",
    "for i in range(seq_length, len(tokens)):\n",
    "    X_sequences.append(tokens[i-seq_length:i])\n",
    "    y.append(tokens[i])\n",
    "\n",
    "X = np.array(X_sequences)\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=len(word_index) + 1)\n",
    "\n",
    "# Step 3: Define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(word_index) + 1, output_dim=50, input_length=seq_length))\n",
    "model.add(SimpleRNN(128))\n",
    "model.add(Dense(len(word_index) + 1, activation='softmax'))\n",
    "\n",
    "# Step 4: Compile and train\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=300, verbose=0)\n",
    "\n",
    "# Step 5: Predict next word\n",
    "def predict_next_word(seed_text, num_words=1):\n",
    "    for _ in range(num_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=seq_length)\n",
    "        predicted_probs = model.predict(token_list, verbose=0)\n",
    "        predicted_index = np.argmax(predicted_probs)\n",
    "        predicted_word = index_word.get(predicted_index, '')\n",
    "        seed_text += ' ' + predicted_word\n",
    "    return seed_text\n",
    "\n",
    "# Test\n",
    "seed = \"machine learning is\"\n",
    "output = predict_next_word(seed, num_words=5)\n",
    "print(\"Generated text:\", output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
