{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b63b967d-2f68-4cfe-95d9-f25c3d695790",
   "metadata": {},
   "source": [
    "# Implementation of Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0183187-21f8-4f72-b18a-4b1e2257bcbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21606\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# The prediction vector of the neural network\n",
    "y_pred=[0.6, 1.29, 1.99, 2.69, 3.4]\n",
    "\n",
    "# The ground truth label\n",
    "y_hat= [1, 1, 2, 2, 4]\n",
    "\n",
    "# Mean squared error\n",
    "MSE = np.sum(np.square(np.subtract(y_hat, y_pred)))/len(y_hat)\n",
    "\n",
    "print(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55089597-f6b7-4493-8601-221c0fb648cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2039728043259361\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# The probabilities predicted by the neural network\n",
    "y_pred = [0.1, 0.3, 0.4, 0.2]\n",
    "\n",
    "# one-hot-encoded ground truth label\n",
    "y_hat =[0, 1, 0, 0]\n",
    "\n",
    "cross_entropy = - np.sum(np.log(y_pred)*y_hat)\n",
    "\n",
    "print(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82fec6ba-0c51-47c5-bdf0-d14f6cbf73d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (Manual): 0.5\n",
      "Mean Absolute Error (sklearn): 0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Example data: actual and predicted values\n",
    "y_true = [3, -0.5, 2, 7]\n",
    "y_pred = [2.5, 0.0, 2, 8]\n",
    "\n",
    "# 1. Manual calculation of MAE\n",
    "mae_manual = sum(abs(t - p) for t, p in zip(y_true, y_pred)) / len(y_true)\n",
    "print(\"Mean Absolute Error (Manual):\", mae_manual)\n",
    "\n",
    "# 2. Using sklearn for MAE\n",
    "mae_sklearn = mean_absolute_error(y_true, y_pred)\n",
    "print(\"Mean Absolute Error (sklearn):\", mae_sklearn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a29fe53-d330-40e7-be3d-6d3f6dcba13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "zip(y_true, y_pred):\n",
    "\n",
    "The zip() function combines two lists element-wise into pairs.\n",
    "For example:\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "y_true = [3, -0.5, 2, 7]\n",
    "y_pred = [2.5, 0.0, 2, 8]\n",
    "list(zip(y_true, y_pred))\n",
    "# Output: [(3, 2.5), (-0.5, 0.0), (2, 2), (7, 8)]\n",
    "for t, p in zip(...):\n",
    "\n",
    "This loop unpacks each pair into variables t (true value) and p (predicted value).\n",
    "Example iterations:\n",
    "Iteration 1: t = 3, p = 2.5\n",
    "Iteration 2: t = -0.5, p = 0.0\n",
    "Iteration 3: t = 2, p = 2\n",
    "Iteration 4: t = 7, p = 8\n",
    "abs(t - p):\n",
    "\n",
    "Calculates the absolute difference between each true and predicted value:\n",
    "abs(3 - 2.5) = 0.5\n",
    "abs(-0.5 - 0.0) = 0.5\n",
    "abs(2 - 2) = 0\n",
    "abs(7 - 8) = 1\n",
    "sum(...):\n",
    "\n",
    "The sum() function adds all these absolute differences together:\n",
    "\n",
    "0.5+0.5+0+1=2.0\n",
    "/ len(y_true):\n",
    "\n",
    "Finally, we divide by the number of elements in y_true to get the average difference:\n",
    "0.5\n",
    "This result, 0.5, is the Mean Absolute Error (MAE), which measures the average magnitude of prediction errors. Smaller MAE values indicate more accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacf36b2-1f99-4628-8e46-e5247e0bb2e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c428fe17-effc-4ae9-971c-ac78e68b05ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Huber Loss (Manual): 0.1875\n",
      "Huber Loss (sklearn HuberRegressor): 0.1193383968600865\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def huber_loss(y_true, y_pred, epsilon=1.0):\n",
    "    \"\"\"\n",
    "    Calculate the Huber loss manually.\n",
    "    \"\"\"\n",
    "    error = np.array(y_true) - np.array(y_pred)\n",
    "    loss = np.where(np.abs(error) <= epsilon, 0.5 * error ** 2, epsilon * (np.abs(error) - 0.5 * epsilon))\n",
    "    return np.mean(loss)\n",
    "\n",
    "# Example data\n",
    "y_true = [3, -0.5, 2, 7]\n",
    "y_pred = [2.5, 0.0, 2, 8]\n",
    "\n",
    "# Manual Huber loss calculation\n",
    "huber_loss_manual = huber_loss(y_true, y_pred, epsilon=1.0)\n",
    "print(\"Huber Loss (Manual):\", huber_loss_manual)\n",
    "\n",
    "# Using sklearn HuberRegressor\n",
    "huber = HuberRegressor(epsilon=1.0)\n",
    "huber.fit(np.array(y_pred).reshape(-1, 1), y_true)\n",
    "y_predicted = huber.predict(np.array(y_pred).reshape(-1, 1))\n",
    "huber_loss_sklearn = huber_loss(y_true, y_predicted)\n",
    "print(\"Huber Loss (sklearn HuberRegressor):\", huber_loss_sklearn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de8e2f38-dd75-49a8-a505-dc648d1f0402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Entropy Loss (Manual): 0.08916873598468311\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cross_entropy_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the cross-entropy loss manually.\n",
    "    \n",
    "    Args:\n",
    "        y_true (list or array): True labels (one-hot encoded).\n",
    "        y_pred (list or array): Predicted probabilities.\n",
    "\n",
    "    Returns:\n",
    "        float: The cross-entropy loss.\n",
    "    \"\"\"\n",
    "    # Clip predictions to avoid log(0) error\n",
    "    y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "    loss = -np.sum(y_true * np.log(y_pred)) / len(y_true)\n",
    "    return loss\n",
    "\n",
    "# Example data\n",
    "y_true = [1, 0, 0, 0]  # One-hot encoded for class 0\n",
    "y_pred = [0.7, 0.1, 0.1, 0.1]  # Predicted probabilities\n",
    "\n",
    "# Calculate cross-entropy loss\n",
    "loss = cross_entropy_loss(y_true, y_pred)\n",
    "print(\"Cross-Entropy Loss (Manual):\", loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0d25f3d-17ce-44d7-af92-12db2b66a2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hinge Loss (Manual): 0.425\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def hinge_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the hinge loss manually.\n",
    "    \n",
    "    Args:\n",
    "        y_true (list or array): True labels (1 or -1).\n",
    "        y_pred (list or array): Predicted scores.\n",
    "        \n",
    "    Returns:\n",
    "        float: The hinge loss.\n",
    "    \"\"\"\n",
    "    # Ensure labels are 1 or -1\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    # Hinge loss formula: max(0, 1 - y_true * y_pred)\n",
    "    loss = np.maximum(0, 1 - y_true * y_pred)\n",
    "    \n",
    "    # Return mean loss\n",
    "    return np.mean(loss)\n",
    "\n",
    "# Example data\n",
    "y_true = [1, -1, 1, -1]  # True labels (+1 or -1)\n",
    "y_pred = [0.8, -0.5, 0.7, -0.3]  # Predicted scores\n",
    "\n",
    "# Calculate hinge loss\n",
    "loss = hinge_loss(y_true, y_pred)\n",
    "print(\"Hinge Loss (Manual):\", loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298b51e5-e2c1-41ea-8a06-e4a9eca022a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
