{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dbb6caf-7f56-4bcb-a58e-7a1b96e52715",
   "metadata": {},
   "source": [
    "# Implementation of Loss Functions using Libraries in python and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6df7d6a7-238b-4f82-ac82-069a0475c92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Regression Model...\n",
      "Epoch 0, MSE Loss: 40.5925\n",
      "Epoch 10, MSE Loss: 0.2198\n",
      "Epoch 20, MSE Loss: 0.1864\n",
      "Epoch 30, MSE Loss: 0.1842\n",
      "Epoch 40, MSE Loss: 0.1856\n",
      "\n",
      "Training Classification Model...\n",
      "Epoch 0, BCE Loss: 0.8422\n",
      "Epoch 10, BCE Loss: 0.8046\n",
      "Epoch 20, BCE Loss: 0.7751\n",
      "Epoch 30, BCE Loss: 0.7518\n",
      "Epoch 40, BCE Loss: 0.7337\n",
      "\n",
      "Testing Models...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Regression Predictions (for [2, 4, -3]): [4.983049392700195, 9.004974365234375, -5.071761131286621]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Classification Predictions (for [1,1], [1,-1], [-1,-1]): [1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# =======================\n",
    "# 1. Data Preparation\n",
    "# =======================\n",
    "# Regression dataset (y = 2x + 1)\n",
    "x_reg = np.linspace(-5, 5, 100).reshape(-1, 1).astype(np.float32)\n",
    "y_reg = 2 * x_reg + 1 + 0.5 * np.random.randn(*x_reg.shape)  # Adding noise\n",
    "\n",
    "# Classification dataset (Binary: 0 or 1)\n",
    "x_cls = np.random.randn(100, 2).astype(np.float32)\n",
    "y_cls = (x_cls[:, 0] * x_cls[:, 1] > 0).astype(np.float32)  # 1 if product > 0 else 0\n",
    "\n",
    "# Loaders\n",
    "batch_size = 16\n",
    "reg_dataset = tf.data.Dataset.from_tensor_slices((x_reg, y_reg)).batch(batch_size).shuffle(100)\n",
    "cls_dataset = tf.data.Dataset.from_tensor_slices((x_cls, y_cls)).batch(batch_size).shuffle(100)\n",
    "\n",
    "\n",
    "# =======================\n",
    "# 2. Neural Network Definitions\n",
    "# =======================\n",
    "# Regression Model\n",
    "reg_model = keras.Sequential([\n",
    "    keras.layers.Dense(1, input_shape=(1,))\n",
    "])\n",
    "\n",
    "# Classification Model\n",
    "cls_model = keras.Sequential([\n",
    "    keras.layers.Dense(1, input_shape=(2,), activation='sigmoid')  # Sigmoid for binary classification\n",
    "])\n",
    "\n",
    "\n",
    "# =======================\n",
    "# 3. Loss Functions and Optimizers\n",
    "# =======================\n",
    "# Regression (MSE)\n",
    "reg_model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.01), \n",
    "                  loss=keras.losses.MeanSquaredError())\n",
    "\n",
    "# Classification (Binary Cross-Entropy)\n",
    "cls_model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.01), \n",
    "                  loss=keras.losses.BinaryCrossentropy())\n",
    "\n",
    "\n",
    "# =======================\n",
    "# 4. Training\n",
    "# =======================\n",
    "# --- Regression Training ---\n",
    "print(\"\\nTraining Regression Model...\")\n",
    "reg_model.fit(reg_dataset, epochs=50, verbose=0, callbacks=[\n",
    "    keras.callbacks.LambdaCallback(on_epoch_end=lambda epoch, logs: \n",
    "        print(f\"Epoch {epoch}, MSE Loss: {logs['loss']:.4f}\") if epoch % 10 == 0 else None)\n",
    "])\n",
    "\n",
    "# --- Classification Training ---\n",
    "print(\"\\nTraining Classification Model...\")\n",
    "cls_model.fit(cls_dataset, epochs=50, verbose=0, callbacks=[\n",
    "    keras.callbacks.LambdaCallback(on_epoch_end=lambda epoch, logs: \n",
    "        print(f\"Epoch {epoch}, BCE Loss: {logs['loss']:.4f}\") if epoch % 10 == 0 else None)\n",
    "])\n",
    "\n",
    "\n",
    "# =======================\n",
    "# 5. Testing and Results\n",
    "# =======================\n",
    "print(\"\\nTesting Models...\")\n",
    "\n",
    "# Regression\n",
    "x_test_reg = np.array([[2.0], [4.0], [-3.0]]).astype(np.float32)\n",
    "y_pred_reg = reg_model.predict(x_test_reg)\n",
    "print(\"Regression Predictions (for [2, 4, -3]):\", y_pred_reg.flatten().tolist())\n",
    "\n",
    "# Classification\n",
    "x_test_cls = np.array([[1.0, 1.0], [1.0, -1.0], [-1.0, -1.0]]).astype(np.float32)\n",
    "y_pred_cls = cls_model.predict(x_test_cls)\n",
    "print(\"Classification Predictions (for [1,1], [1,-1], [-1,-1]):\", (y_pred_cls > 0.5).astype(int).flatten().tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44c751d1-fcaf-42b4-a621-3137c2455f63",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (4183089111.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    '''\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Explanation:\n",
    "Data Preparation:\n",
    "\n",
    "tf.data.Dataset is used for efficient data loading and batching.\n",
    "The regression dataset is generated using y = 2x + 1 with added noise.\n",
    "The classification dataset uses the product of two random numbers to determine labels (1 if product > 0 else 0).\n",
    "Model Definitions:\n",
    "\n",
    "keras.Sequential() creates simple feedforward networks.\n",
    "For regression, a single dense layer with one neuron is used.\n",
    "For classification, a single dense layer with sigmoid activation is used to output probabilities.\n",
    "Loss Functions and Optimizers:\n",
    "\n",
    "MeanSquaredError for regression.\n",
    "BinaryCrossentropy for binary classification.\n",
    "Both use SGD as the optimizer with a learning rate of 0.01.\n",
    "Training:\n",
    "\n",
    "The .fit() method trains both models for 50 epochs.\n",
    "The LambdaCallback prints the loss every 10 epochs.\n",
    "Testing:\n",
    "\n",
    "Predictions are made using .predict() and then formatted using .flatten() or thresholded for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebc667d-d159-49c5-b3c6-a0c04ee1ece9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
